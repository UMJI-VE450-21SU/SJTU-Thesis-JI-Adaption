% = = = = = = = = = = = = = = = = = = = = = %
%             Design Description            %
% = = = = = = = = = = = = = = = = = = = = = %

\let\clearpage\relax
\chapter{Final Design Description \& Analysis}

In this chapter, we will review our selected concepts in details, including engineering design analysis, design description and analysis of ISA and microarchitecture for each pipeline stages.

\section{Engineering Design Analysis}

\subsection{ISA} %sj
As we mentioned in the previous chapter, we select our instruction set architecture (ISA) among three choices: MIPS, ARMv7 and RISC-V. Their advantages and disadvantages are listed in section~\ref{section:isa}.

After discussion, we decide to choose RISC-V ISA as our design standard.

Meanwhile, since our final product implements approximate computing units to accelerate machine learning and neural network computation, customized ISA is necessary for us. RISC-V supports customized instructions and offers abundant design space compared to other two choices.

Besides, we need to balance our workload and supported features. RISC-V supports many pre-defined instructions, with acceptable complexity. After evaluation, we are able to complete our processor design and implement RISC-V ISA in a short period.

\subsection{Microarchitecture} \label{section：Microarchitecture} % sl 
We have used the decision matrix to determine the final design of our processor microarchitecture design. Specifically, we determine to implement superscalar and out-of-order features in our design, matching most of customer requirements. For example, in the aspect of performance, our superscalar out-of-order design provides good performance especially in those computing-intensive tasks. It matches the engineering specifications we set earlier, including supporting instruction dynamic scheduling, etc., and provides a good performance-power-cost balance.

\section{Design Description of ISA} % lzy - consider moving customized instructions to here

Based on RISC-V basic ISA, we further add some customized instructions to perform approximate floating-point computations.

\subsection{Customized Instructions} \label{section：Customized Instructions} %lzy 
For floating-point execution units, especially in our design, we support both accurate computation and approximate computation simultaneously. The advantage of approximate computation over accurate floating point computation is that it is fast and consumes less power. For embedded systems that require high performance, low power consumption, and relatively low computation accuracy, approximate computation units are preferred. In order to support using our approximate floating-point computing units in ordinary C programs, we have added customized instructions to RISC-V F standard extension and D standard extension. These two standard extensions of RISC-V are used to support operations for single-precision floating-point and double-precision floating-point respectively.

\subsubsection{Floating Point Register State}

To support the RISC-V F standard extension instruction set and D extension instruction set, 32 floating-point registers are added, named \texttt{f0} – \texttt{f31}, each \texttt{FLEN} bits wide with a floating-point control and status register \texttt{fcsr} handling the operating mode and exception status of the floating-point unit. For RISC-V standard F extension only,  \texttt{FLEN = 32}. If both F extension and D extension are supported, \texttt{FLEN = 64} such that floating point registers can hold either 32-bit or 64-bit floating point values \quickcitenopage{RISC-V_unprivileged_ISA}. 

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.5\linewidth]{figure/fp-regs.png}
    \caption{RISC-V F register state \quickcitenopage{RISC-V_unprivileged_ISA}.}
    \label{fig:risc-v F register state}
\end{figure}

\subsubsection{Floating Point Customized Instructions}

Similar to the standard floating-point arithmetic instructions with one or two source operands, our customized approximate computation instructions use the R-type format with the OP-FP major opcode \quickcitenopage{RISC-V_unprivileged_ISA}. \texttt{FMULA.S} or \texttt{FMULA.D} performs the approximate single-precision or double-precision floating point multiplication of \texttt{rs1} times \texttt{rs2} respectively and writes the result back to \texttt{rd}. \texttt{FDIVA.S} or \texttt{FDIVA.D} performs the approximate single-precision or double-precision floating point division of \texttt{rs1} by \texttt{rs2} and writes the result back to \texttt{rd}.

The encoding of the 2-bit floating point format field \texttt{fmt} is shown in Illustration~\ref{fig:format field enconding}. For all the instructions in the F extension, it is set to \texttt{S(00)}, and for all instructions in the D extension, it is set to \texttt{D(01)} \quickcitenopage{RISC-V_unprivileged_ISA}.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.5\linewidth]{figure/fmt.png}
    \caption{Format field encoding \quickcitenopage{RISC-V_unprivileged_ISA}.}
    \label{fig:format field enconding}
\end{figure}

All the floating-point operations that require rounding can select the corresponding rounding mode through \texttt{rm} field. The encoding for \texttt{rm} field is shown in Illustration~\ref{fig:rounding mode encoding} \quickcitenopage{RISC-V_unprivileged_ISA}.
\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/rm-encoding.png}
    \caption{Rounding mode encoding \quickcitenopage{RISC-V_unprivileged_ISA}.}
    \label{fig:rounding mode encoding}
\end{figure}

Finally, our customized approximate computation instructions are listed in Illustration~\ref{fig:customized approximated computation instructions}. The formats should be \texttt{fmula.s}/\texttt{fdiva.s}/\texttt{fmula.d}/\texttt{fdiva.d} \texttt{rd rs1 rs2}. 
\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/instruction.png}
    \caption{Customized approximated computation instructions.}
    \label{fig:customized approximated computation instructions}
\end{figure}

\section{Design Description of Microarchitecture}
In this part, we will explain our design details of each microarchitecture pipeline stages. A simplified pipeline design diagram is shown in Illustration~\ref{fig:pipeline}. Our processor supports 4-way superscalar execution and instruction dynamic scheduling, dividing into two parts: frontend and backend. In the frontend, there are 4 stages: instruction fetch (IF), instruction decode (ID), register renaming (RR), dispatch (DP). In the backend, there are 5 stages: issue (IS), register file (RF), execution (EX), write back (WB), and commit (CM).

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figure/design.png}
    \caption{Simplified pipeline diagram.}
    \label{fig:pipeline}
\end{figure}

\subsection{Instruction Fetch \& Branch Prediction} % syq
The instruction fetch stage is the first stage of the whole pipeline shown in Illustration~\ref{fig:pipeline}. It reads instructions from memory and sends to the subsequent stages. The branch predictor is also implemented in this stage. As is shown in Illustration~\ref{fig:br_pred}, the branch predictor consists of both direction predictor and branch target buffer (BTB). The direction predictor implements a 2-bit saturation counter to represent the possibility of branch taken: 00 - strongly not taken, 01 - weakly not taken, 10 - weakly taken, 11 - strongly taken. We predict the next program counter (PC) address based on the prediction feedback from re-order buffer (ROB) and the prediction output of the branch predictor.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.8\textwidth]{figure/branch_predictor.png}
    \caption{Branch predictor diagram.}
    \label{fig:br_pred}
\end{figure}

\subsection{Fetch Buffer} % syq
The fetch buffer serves as a buffer to store the fetched instructions if they can not be dispatched at once due to the congestion of later stages. The buffer is implemented as a first-in-first-out (FIFO) queue to ensure an in-order dispatch of instructions. It is not used in the final design, but it is useful if we want to further support RISC-V C extention, as the output of this stage is always 4 instructions but the input from the previous stage may be at most 8 instructions.

\subsection{Instruction Decode} %sj
In this part, we decode the input instructions into micro operations (\texttt{uops}). We implement four decoders to decode four instructions simultaneously.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.5\textwidth]{figure/decode.png}
    \caption{4-way decoder.}
    \label{fig:decoder}
\end{figure}

RISC-V instructions can be classified by their formats. Illustration~\ref{fig:RISCV_inst} shows all instruction types. The decoders first sort input instructions according to the format table. Then, the decoders analyze information in each part of the instruction and translate them into micro operations that can be processed by the following stages.

Micro operations are designed as a data structure, including source architectural registers, destination register, used immediate and operation code. Therefore, other stages can fetch needed information conveniently from micro operations.

\subsection{Register Renaming} % sj
In this part, we rename architectural registers and assign physical registers to them. Besides, the renaming part should also mark physical registers in the retiring instructions as free.

The main purpose of register renaming is to break anti-dependency (write after read, WAR) and output dependency (write after write, WAW) between architectural registers. Therefore, instructions with these dependencies can be pipelined together in execution stage, which further improves the performance of the processor. Illustration~\ref{fig:waw_war} shows how to break WAR and WAW in this stage. On the other hand, the renaming part should protect and record the true dependency (read after write, RAW) so that an instruction can read and get the right source register. For special architectural register, i.e., \texttt{x0}, the renaming part should protect it from being assigned to other physical registers.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.5\textwidth]{figure/waw.png}
    \includegraphics[width=0.5\textwidth]{figure/war.png}
    \caption{Write after read (WAR) and write after write (WAW) dependency.}
    \label{fig:waw_war}
\end{figure}

Our renaming stage is based on an ``explicit renaming'' or ``physical register file'' out-of-order core design. A physical register file (128 entries), containing many more registers than the ISA dictates (32 entries for integer and 32 entries for floating points), holds both the committed architectural register state and speculative register state. The retirement rename allocation table (rRAT) contains the information needed to recover the committed state. The mapping relation will be recorded in the mapping table, also called rename allocation table (RAT). When the operands in the instructions are renamed, their register specifiers are explicitly updated to point to physical registers located in the physical register file. Illustration~\ref{fig:rename} shows the rename logic between two instructions and their architectural registers. Since our 4-way renaming stage can rename 4 instructions simultaneously, the real renaming logic is far more complex than the given example.

Since we use unified physical register file in the register file stage, integer architectural registers and floating point architectural registers share the same register ``pool'' and addressing structure. For this reason, we rename their physical registers together and do not take their differences into consideration in this stage.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.8\textwidth]{figure/rename-pipeline.png}
    \caption{Register renaming logic\quickcitenopage{Boom}.}
    \label{fig:rename}
\end{figure}

We implement a free list to record the usage of physical registers. When a physical register is assigned to an architecture register, it will be marked as ``busy'' in the free list. On the other hand, when it is retired by the retired instructions, it will be marked as ``free''. Illustration~\ref{fig:mapping} shows the relation between mapping table, free list and rRAT.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.65\textwidth]{figure/map_rename.png}
    \caption{Rename stage with free list, mapping table and rRAT.}
    \label{fig:mapping}
\end{figure}

To resolve data hazards, we apply a conservative strategy. When an architectural register $x_a$ is re-assigned to a new physical register $r_b$, its previous physical register $r_a$ will be recorded. Cycles later, when the architectural register $x_a$ is retired by its instruction, its previous physical register $r_a$ will be freed or assigned to another architecture register. At that time, the free list or the mapping table is updated by the new mapping relation. Besides, rRAT is also refreshed by the mapping relation between architectural register $x_a$ and its new physical register $r_b$ so that the rename stage can quickly recover from mis-prediction, interrupts or exceptions.

When a branch mis-prediction happens, i.e., when we want to recover the processor states, the mapping table and the free list will recover their mapping relation and free stages from rRAT. The recover process takes only one clock cycle, which means that our rename stage can quickly response to branch mis-predictions, interrupts or exceptions. This feature can improve our instructions per cycle (IPC) in programs with many branch mis-predictions, interrupts or exceptions.

\subsection{Dispatch} %sl

Dispatch is the last stage in the frontend and also the last in-order stage. In this part, we write the instructions from the previous stage into the re-order buffer (ROB) the backend and then dispatch these instructions to the corresponding issue units according to the \texttt{iq\_code} field in the uops. We support dispatching 4 instruction at one time. To reduce the logic complexity of input selection in the issue stage, we design our dispatch stage based on collapsing logic, shown in Illustration~\ref{fig:dp-1}. The instructions will always be dispatched to the top space in the inputs of backend without any bubbles.

\begin{figure}[!htp]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figure/dispatch.png}
        \caption{Collapsing dispatch logic.}
        \label{fig:dp-1}
    \end{subfigure}
    ~
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figure/dispatch-nc.png}
        \caption{Non-collapsing dispatch logic.}
        \label{fig:dp-2}
    \end{subfigure}
    \caption{Two different dispatch logic design.}
    \label{fig:dispatch}
\end{figure}

On the contrary, a non-collapsing dispatcher is shown in Illustration~\ref{fig:dp-2}. The logic is simpler, but it will further complicate the input selection logic and increase the delay in issue stage, especially for memory instructions, which usually require strict memory access order to keep the consistency.

\subsection{Issue} %sl
In this part, we accept the input of instructions from the frontend, track the data and structural dependency between instructions, select part of the ready instructions and issue them to the register file and the execution units. This is also the critical point between in-order and out-of-order stages in our microarchitecture design, and is the key component to implement out-of-order scheduling algorithm.

In our design, we implement 3 issue units: integer issue unit, memory issue unit and floating-point issue unit. All 3 issue units are able to accept four instructions at one time, but the outputs differ, dependent on the design of execution units.

\subsubsection{Issue Unit for Integer \& Floating Point} %sl
We design the input selection logic to assign the input instructions to free space in the issue units. The logic of instruction assignment is simple. We just put the instructions in the free space from top to bottom. Meanwhile, we design the output selection logic to issue instructions whose dependency is ready to the subsequent pipeline stages. The output width depends on the execution width. In our design, we can issue at most 3 integer instructions or 2 floating-point instructions simultaneously. Among all the ready instructions, we also select from top to bottom. A simple example of issue unit for integer instructions is shown in Illustration~\ref{fig:iq-int}.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.3\textwidth]{figure/iq1.png}
    \caption{Example of issue logic for integer instructions (L for load, S for store).}
    \label{fig:iq-int}
\end{figure}

\subsubsection{Issue Unit for Memory Access} %sl
Due to the special characteristics of memory access instructions, the selection logic of the issue unit for memory access is different from the logic of the other two issue units. The main principle is to keep the memory consistency, which is a big challenge for out-of-order execution design. It is easy to track data dependency in registers, but it is much more difficult to track the dependency in memory. For example, assuming that the same memory address is stored in the registers \texttt{x1} and \texttt{x2}, for the case that we first store the data to \texttt{[x4]} and then load the data from \texttt{[x3]}, we cannot directly determine whether there exists potential dependency between the two instructions. 

Thus, in our processor design, we use a relatively conservative way to achieve memory consistency. We consider each store instruction as a barrier, i.e., while load instructions can be executed out-of-order, we can issue the store instructions only when it is at the top of our issue unit. As a result, similar to dispatch unit, we design a collapsing structure in the issue unit for memory access. Each time one instruction is issued, all the instructions are ``compressed'' to the top, and the input instructions are added to the tail of the unit. For the output selection logic, if there are remaining store instructions, only the store instruction at the top or the load instructions before any store instructions can be issued.

A simple example is shown in Illustration~\ref{fig:iq-mem}. At the top of the issue unit is a store instruction, which will be issued in this clock cycle. Then all the remaining instructions are pushed to the top, and new instructions are added below.

\begin{figure}[!htp]
    \centering
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=0.75\textwidth]{figure/iq2.png}
        \caption{Example of issue unit logic: stage 1.}
        \label{fig:iq-mem-1}
    \end{subfigure}
    ~
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=0.3\textwidth]{figure/iq3.png}
        \caption{Example of issue unit logic: stage 2.}
        \label{fig:iq-mem-2}
    \end{subfigure}
    \caption{Example of issue unit logic for memory access.}
    \label{fig:iq-mem}
\end{figure}


\subsubsection{Scoreboard} %sl
Although register renaming may resolve anti-dependency and output dependency, it cannot resolve true dependency, i.e., read-after-write (RAW) dependency, which is usually the crucial bottleneck to further improve instruction level parallelism. In our design, scoreboard is mainly used for tracking data dependency between instructions and sending wake-up signals to the issue units.

The width of scoreboard matches the depth of our physical register file. First, it accepts input from dispatch stage, which is the last in-order stage and sets the busy bits in the scoreboard. Second, it accepts input from write back stage, which clears the busy bits in the scoreboard. Finally, it accepts the query requests from the issue units and returns whether the requiring source registers are ready or not.

Illustration~\ref{fig:sb} shows an example of how the scoreboard helps to track RAW dependency between two instructions. Here the second instruction depends on the result of the first instruction. First, when the two instructions enter the dispatch stage, set both \texttt{X} and \texttt{Y} as busy, marking them as in-flight instructions (Illustration~\ref{fig:sb-1}). Second, the first instruction is issued to the later stages of the pipeline (Illustration~\ref{fig:sb-2}). Third, when the first instruction is completed and write back to the register file, set \texttt{X} as not busy (Illustration~\ref{fig:sb-3}). At last, as \texttt{X} is not busy any more, the second instruction checks the scoreboard, finding that it is also ready to issue, and we issue it to the register file and corresponding execution units (Illustration~\ref{fig:sb-4}).

\begin{figure}[!htp]
    \centering
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\textwidth]{figure/sb1.png}
        \caption{Example of scoreboard: stage 1.}
        \label{fig:sb-1}
    \end{subfigure}
    ~
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\textwidth]{figure/sb2.png}
        \caption{Example of scoreboard: stage 2.}
        \label{fig:sb-2}
    \end{subfigure}
    
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\textwidth]{figure/sb3.png}
        \caption{Example of scoreboard: stage 3.}
        \label{fig:sb-3}
    \end{subfigure}
    ~
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\textwidth]{figure/sb4.png}
        \caption{Example of scoreboard: stage 4.}
        \label{fig:sb-4}
    \end{subfigure}
    \caption{RAW dependency tracking with scoreboard.}
    \label{fig:sb}
\end{figure}

\subsection{Register File} %sl

As mentioned in the register rename part, our processor resolves anti-dependency and output dependency based on physical register file (PRF) design. In our design, there is only one unified PRF with 128 entries. Bypassing logic is implemented to handle the case that source operands are identical with destination operands. 

Compared to other methods of register renaming, there are several advantages of using PRF. There is no need to move the data frequently, as the data always stays in the PRF. We don't need to add selectors for instructions to determine which register file to use. Furthermore, It is also easy to recover from branch mis-predictions, which helps to further explore the instruction level parallelism and improve the performance.

\subsection{Execution} %sl

An execution pipe is a set of function units. In our microarchitecture design, we have 6 execution pipes in total (3 for integer, 1 for memory access and 2 for floating-point), shown in Illustration~\ref{fig:pipe}.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.4\textwidth]{figure/pipe.png}
    \caption{Execution pipes.}
    \label{fig:pipe}
\end{figure}

\subsubsection{Execution Units for Integer} % sl
There are 3 pipes for integer instructions. Pipe 0 and 1 encapsulate arithmetic logic units (ALU), which perform normal integer arithmetic operations except multiplication and division, and branch units, while pipe 2 is used for integer multiplication and division. ALU and branch units require one clock cycle delay, while integer multiplication and division require more than one clock cycle delay and they are blocking. Instead of using commercial intellectual property (IP) cores, we implement integer multiplier and divider by ourselves based on open source designs.

\subsubsection{Execution Units for Memory Access} %sl
Pipe 3 is for memory access, i.e., load and store instructions, and it is blocking. When a load or store instruction enter this pipe, the processor will send the address, write-enable signal, data to be written and its size (if applicable) to the memory, and receive the data and valid signal from the memory.

\subsubsection{Execution Units for Floating Point} %sj
There are 2 pipes for floating-point instructions. Both pipe 4 and 5 encapsulate floating-point units (FPU) and approximate computing units (ACU). Each pipe consists of two function units, FPU for general floating-point computation and ACU for approximate computation.

\subsection{Write Back} %sl

When an instruction is completed, the result will be written back to the register file and clear the corresponding busy bit in the scoreboard if the destination operand is valid.

\subsection{Commit} %sj
The commit stage is the last stage in the processor to handle instructions, consisting of a re-order buffer (ROB) that tracks the state of all in-flight instructions in the pipeline. Besides, the ROB also records the order of instructions before they are dispatched into issue queues. The ROB is actually a first-in-first-out (FIFO) queue.

When an instruction is renamed and put into the ROB, it will be marked as ``busy'' in the ROB. On the other hand, when it enters the commit stage, it informs the ROB and is marked ``not busy''. Once the ``head'' of the ROB is no longer ``busy'', the instruction is retired, and the architectural state of the processor is updated. Illustration~\ref{fig:rob} shows the structure of our ROB design.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.6\textwidth]{figure/rob.png}
    \caption{Re-order buffer (ROB).}
    \label{fig:rob}
\end{figure}

Since we have 4-way renaming and 6-way execution, the ROB can accept 4 instructions input and pop 6 instructions simultaneously. Some special techniques need to be applied in the final circuit implementation, like interleaving, to satisfy the requirement.

Branch mis-predictions, interrupts or exceptions are handled when they are at the commit head. When mis-predictions, interrupts or exceptions happen, their following instructions are marked as illegal and their previous instructions are all retired normally. The ROB should be cleared and flushed then, and send the ``recover'' signal to all the previous stages in the pipeline.
